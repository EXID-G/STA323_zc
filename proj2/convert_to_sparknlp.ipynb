{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/module/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a405a032-7eb7-4258-809a-62aa132ea318;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      ":: resolution report :: resolve 117ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a405a032-7eb7-4258-809a-62aa132ea318\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/4ms)\n",
      "24/06/07 14:34:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "# from pyspark.sql.types import StringType, StructType, StructField\n",
    "from pyspark.sql.types import *\n",
    "# import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"Spark NLP\") \\\n",
    "#     .master(\"local[*]\") \\\n",
    "#     .config(\"spark.driver.memory\", \"16G\") \\\n",
    "#     .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "#     .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\") \\\n",
    "#     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade transformers[onnx]==4.35.2 optimum sentencepiece onnx==1.14.0\n",
    "# MODEL_NAME = \"flan-t5-small\"\n",
    "MODEL_NAME = \"best_model\"\n",
    "EXPORT_PATH = f\"onnx_models/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Framework not specified. Using pt to export the model.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "***** Exporting submodel 1/3: T5Stack *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "\n",
      "***** Exporting submodel 2/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/modeling_utils.py:873: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
      "\n",
      "***** Exporting submodel 3/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:508: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "Post-processing the exported models...\n",
      "Deduplicating shared (tied) weights...\n",
      "Could not find ONNX initializer for torch parameter decoder.embed_tokens.weight. decoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Could not find ONNX initializer for torch parameter encoder.embed_tokens.weight. encoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tdecoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tencoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tshared.weight: {'shared.weight'}\n",
      "Could not find ONNX initializer for torch parameter decoder.embed_tokens.weight. decoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Could not find ONNX initializer for torch parameter encoder.embed_tokens.weight. encoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tdecoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tencoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tshared.weight: {'shared.weight'}\n",
      "The two models proto have different outputs (33 and 17 outputs). Constant outputs will be added to unify the two models outputs. This is expected for encoder-decoder models where cached cross-attention key/values are constant outputs, omitted in the model with KV cache.\n",
      "Adding a constant output for present.0.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.0.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "\n",
      "Validating ONNX model onnx_models/best_model/encoder_model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (2, 16, 512) matches (2, 16, 512)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model onnx_models/best_model/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.2.decoder.key, present.4.encoder.key, present.2.decoder.value, present.5.encoder.value, present.7.decoder.key, present.7.decoder.value, present.2.encoder.value, present.1.decoder.key, present.0.decoder.key, present.4.decoder.value, present.4.decoder.key, present.2.encoder.key, present.1.decoder.value, present.3.decoder.key, present.0.encoder.key, present.3.encoder.value, present.6.encoder.key, logits, present.6.encoder.value, present.3.decoder.value, present.1.encoder.value, present.0.decoder.value, present.6.decoder.value, present.0.encoder.value, present.7.encoder.value, present.7.encoder.key, present.3.encoder.key, present.1.encoder.key, present.5.decoder.value, present.5.encoder.key, present.4.encoder.value, present.5.decoder.key, present.6.decoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 16, 32128) matches (2, 16, 32128)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 1.33514404296875e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model onnx_models/best_model/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.5.decoder.value, present.4.decoder.value, present.4.decoder.key, present.2.decoder.key, present.3.decoder.value, present.5.decoder.key, present.0.decoder.value, present.2.decoder.value, present.6.decoder.value, present.1.decoder.value, present.7.decoder.key, logits, present.3.decoder.key, present.6.decoder.key, present.7.decoder.value, present.1.decoder.key, present.0.decoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 1, 32128) matches (2, 1, 32128)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 1e-05:\n",
      "- present.6.decoder.value: max diff = 1.33514404296875e-05.\n",
      " The exported model was saved at: onnx_models/best_model\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export onnx --task text2text-generation-with-past --model {MODEL_NAME} {EXPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 810568\n",
      "drwxr-xr-x 2 root root      4096 Jun  7 14:11 assets\n",
      "-rw-r--r-- 1 root root      1517 Jun  7 14:34 config.json\n",
      "-rw-r--r-- 1 root root 232553676 Jun  7 14:34 decoder_model.onnx\n",
      "-rw-r--r-- 1 root root 232784389 Jun  7 14:35 decoder_model_merged.onnx\n",
      "-rw-r--r-- 1 root root 219953983 Jun  7 14:35 decoder_with_past_model.onnx\n",
      "-rw-r--r-- 1 root root 141456358 Jun  7 14:34 encoder_model.onnx\n",
      "-rw-r--r-- 1 root root       142 Jun  7 14:34 generation_config.json\n",
      "-rw-r--r-- 1 root root      2543 Jun  7 14:34 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root    791656 Jun  7 14:34 spiece.model\n",
      "-rw-r--r-- 1 root root   2424156 Jun  7 14:34 tokenizer.json\n",
      "-rw-r--r-- 1 root root     20817 Jun  7 14:34 tokenizer_config.json\n",
      "total 776\n",
      "-rw-r--r-- 1 root root 791656 Jun  7 14:34 spiece.model\n"
     ]
    }
   ],
   "source": [
    "!ls -l {EXPORT_PATH}\n",
    "\n",
    "! mkdir -p {EXPORT_PATH}/assets\n",
    "! mv -t {EXPORT_PATH}/assets {EXPORT_PATH}/spiece.model\n",
    "!ls -l {EXPORT_PATH}/assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer.loadSavedModel.\n: java.lang.NoClassDefFoundError: com/amazonaws/AmazonServiceException\n\tat com.johnsnowlabs.ml.util.LoadExternalModel$.modelSanityCheck(LoadExternalModel.scala:137)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel.loadSavedModel(T5Transformer.scala:635)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel.loadSavedModel$(T5Transformer.scala:633)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer$.loadSavedModel(T5Transformer.scala:694)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer.loadSavedModel(T5Transformer.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.ClassNotFoundException: com.amazonaws.AmazonServiceException\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\t... 17 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparknlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m T5 \u001b[38;5;241m=\u001b[39m T5Transformer\u001b[38;5;241m.\u001b[39mloadSavedModel(EXPORT_PATH, spark)\\\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;241m.\u001b[39msetUseCache(\u001b[38;5;28;01mTrue\u001b[39;00m) \\\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;241m.\u001b[39msetTask(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;241m.\u001b[39msetMaxOutputLength(\u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/annotator/seq2seq/t5_transformer.py:402\u001b[0m, in \u001b[0;36mT5Transformer.loadSavedModel\u001b[0;34m(folder, spark_session)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads a locally saved model.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    The restored model\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparknlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _T5Loader\n\u001b[0;32m--> 402\u001b[0m jModel \u001b[38;5;241m=\u001b[39m _T5Loader(folder, spark_session\u001b[38;5;241m.\u001b[39m_jsparkSession)\u001b[38;5;241m.\u001b[39m_java_obj\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m T5Transformer(java_model\u001b[38;5;241m=\u001b[39mjModel)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal/__init__.py:247\u001b[0m, in \u001b[0;36m_T5Loader.__init__\u001b[0;34m(self, path, jspark)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, jspark):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_T5Loader, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer.loadSavedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, path, jspark)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:27\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m(ExtendedJavaWrapper, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(java_obj)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_java_obj(java_obj, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:37\u001b[0m, in \u001b[0;36mExtendedJavaWrapper.new_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_java_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m, java_class, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_java_obj(java_class, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/pyspark/ml/wrapper.py:86\u001b[0m, in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_new_java_array\u001b[39m(pylist, java_class):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Create a Java array of given java_class type. Useful for\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    calling a method with a Scala Array from Python with Py4J.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If the param pylist is a 2D array, then a 2D java array will be returned.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    The returned 2D java array is a square, non-jagged 2D array that is big\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    enough for all elements. The empty slots in the inner Java arrays will\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    be filled with null to make the non-jagged 2D array.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    pylist : list\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        Python list to convert to a Java Array.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    java_class : :py:class:`py4j.java_gateway.JavaClass`\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m        Java class to specify the type of Array. Should be in the\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m        form of sc._gateway.jvm.* (sc is a valid Spark Context).\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;124;03m        Example primitive Java classes:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m        - basestring -> sc._gateway.jvm.java.lang.String\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        - int -> sc._gateway.jvm.java.lang.Integer\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        - float -> sc._gateway.jvm.java.lang.Double\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        - bool -> sc._gateway.jvm.java.lang.Boolean\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    :py:class:`py4j.java_collections.JavaArray`\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m      Java Array of converted pylist.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m     99\u001b[0m     java_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx \u001b[38;5;241m=\u001b[39m sql_ctx\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, jdf, batch_id):\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer.loadSavedModel.\n: java.lang.NoClassDefFoundError: com/amazonaws/AmazonServiceException\n\tat com.johnsnowlabs.ml.util.LoadExternalModel$.modelSanityCheck(LoadExternalModel.scala:137)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel.loadSavedModel(T5Transformer.scala:635)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel.loadSavedModel$(T5Transformer.scala:633)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer$.loadSavedModel(T5Transformer.scala:694)\n\tat com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer.loadSavedModel(T5Transformer.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.ClassNotFoundException: com.amazonaws.AmazonServiceException\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\t... 17 more\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "\n",
    "T5 = T5Transformer.loadSavedModel(EXPORT_PATH, spark)\\\n",
    "  .setUseCache(True) \\\n",
    "  .setTask(\"qa:\") \\\n",
    "  .setMaxOutputLength(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5.write().overwrite().save(f\"{MODEL_NAME}_spark_nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {EXPORT_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
