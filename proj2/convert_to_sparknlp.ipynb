{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/module/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a81ab276-4a86-4413-9d78-81c3f91f70d2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;3.3.0 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.5.3 in central\n",
      "\tfound joda-time#joda-time;2.9.5 in central\n",
      "\tfound org.joda#joda-convert;1.8.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 608ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;3.3.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.9.5 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.joda#joda-convert;1.8.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.5.3 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a81ab276-4a86-4413-9d78-81c3f91f70d2\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/11ms)\n",
      "24/06/03 19:56:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "# from pyspark.sql.types import StringType, StructType, StructField\n",
    "from pyspark.sql.types import *\n",
    "# import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/03 19:56:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "model_name_path = \"/STA323_zc/proj2/flan-t5-small\"\n",
    "EXPORT_PATH = f\"nlp_{model_name_path.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "\n",
      "***** Exporting submodel 1/3: T5Stack *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "\n",
      "***** Exporting submodel 2/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/modeling_utils.py:873: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
      "\n",
      "***** Exporting submodel 3/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/envs/sp/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:508: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "Post-processing the exported models...\n",
      "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
      "The two models proto have different outputs (33 and 17 outputs). Constant outputs will be added to unify the two models outputs. This is expected for encoder-decoder models where cached cross-attention key/values are constant outputs, omitted in the model with KV cache.\n",
      "Adding a constant output for present.0.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.0.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "\n",
      "Validating ONNX model nlp_flan-t5-small/encoder_model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (2, 16, 512) matches (2, 16, 512)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model nlp_flan-t5-small/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.6.encoder.key, present.5.encoder.value, present.4.encoder.value, present.0.encoder.value, present.2.encoder.key, present.5.decoder.value, present.0.decoder.key, present.1.decoder.value, present.6.decoder.key, present.6.decoder.value, present.5.encoder.key, present.7.decoder.key, present.1.encoder.key, present.4.decoder.value, logits, present.5.decoder.key, present.0.decoder.value, present.3.decoder.value, present.3.encoder.value, present.3.encoder.key, present.1.encoder.value, present.7.encoder.value, present.0.encoder.key, present.6.encoder.value, present.4.decoder.key, present.2.encoder.value, present.7.decoder.value, present.2.decoder.value, present.1.decoder.key, present.4.encoder.key, present.7.encoder.key, present.2.decoder.key, present.3.decoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 16, 32128) matches (2, 16, 32128)\n",
      "\t\t-[x] values not close enough, max diff: 4.1961669921875e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 1.5616416931152344e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.6702880859375e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.5272369384765625e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.5033950805664062e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model nlp_flan-t5-small/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.5.decoder.value, present.0.decoder.key, present.1.decoder.value, present.6.decoder.key, present.6.decoder.value, present.1.decoder.key, present.4.decoder.key, present.7.decoder.key, present.7.decoder.value, present.4.decoder.value, logits, present.2.decoder.key, present.5.decoder.key, present.0.decoder.value, present.3.decoder.value, present.2.decoder.value, present.3.decoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 1, 32128) matches (2, 1, 32128)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 1e-05:\n",
      "- logits: max diff = 4.1961669921875e-05\n",
      "- present.3.decoder.value: max diff = 1.5616416931152344e-05\n",
      "- present.5.decoder.value: max diff = 2.6702880859375e-05\n",
      "- present.6.decoder.value: max diff = 2.5272369384765625e-05\n",
      "- present.7.decoder.value: max diff = 2.5033950805664062e-05.\n",
      " The exported model was saved at: nlp_flan-t5-small\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export onnx --task text2text-generation-with-past --model {model_name_path} {EXPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 809792\n",
      "drwxr-xr-x 2 root root      4096 Jun  3 19:59 assets\n",
      "-rw-r--r-- 1 root root      1537 Jun  3 19:56 config.json\n",
      "-rw-r--r-- 1 root root 232553676 Jun  3 19:58 decoder_model.onnx\n",
      "-rw-r--r-- 1 root root 232784389 Jun  3 19:58 decoder_model_merged.onnx\n",
      "-rw-r--r-- 1 root root 219953983 Jun  3 19:58 decoder_with_past_model.onnx\n",
      "-rw-r--r-- 1 root root 141456358 Jun  3 19:57 encoder_model.onnx\n",
      "-rw-r--r-- 1 root root       142 Jun  3 19:56 generation_config.json\n",
      "-rw-r--r-- 1 root root      2201 Jun  3 19:56 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root   2422256 Jun  3 19:56 tokenizer.json\n",
      "-rw-r--r-- 1 root root     20771 Jun  3 19:56 tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: 'nlp_flan-t5-small/assets/spiece.model' and 'nlp_flan-t5-small/assets/spiece.model' are the same file\n"
     ]
    }
   ],
   "source": [
    "!ls -l {EXPORT_PATH}\n",
    "\n",
    "! mkdir -p {EXPORT_PATH}/assets\n",
    "! mv -t {EXPORT_PATH}/assets {EXPORT_PATH}/assets/spiece.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 776\n",
      "-rw-r--r-- 1 root root 791656 Jun  3 19:56 spiece.model\n"
     ]
    }
   ],
   "source": [
    "!ls -l {EXPORT_PATH}/assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: savedModel file saved_model.pb not found in folder nlp_flan-t5-small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparknlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m T5 \u001b[38;5;241m=\u001b[39m T5Transformer\u001b[38;5;241m.\u001b[39mloadSavedModel(EXPORT_PATH, spark)\\\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;241m.\u001b[39msetUseCache(\u001b[38;5;28;01mTrue\u001b[39;00m) \\\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;241m.\u001b[39msetTask(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;241m.\u001b[39msetMaxOutputLength(\u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/annotator.py:11507\u001b[0m, in \u001b[0;36mloadSavedModel\u001b[0;34m(folder, spark_session)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal.py:352\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, path, jspark)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal.py:165\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/sparknlp/internal.py:175\u001b[0m, in \u001b[0;36mnew_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/pyspark/ml/wrapper.py:86\u001b[0m, in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_new_java_array\u001b[39m(pylist, java_class):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Create a Java array of given java_class type. Useful for\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    calling a method with a Scala Array from Python with Py4J.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If the param pylist is a 2D array, then a 2D java array will be returned.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    The returned 2D java array is a square, non-jagged 2D array that is big\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    enough for all elements. The empty slots in the inner Java arrays will\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    be filled with null to make the non-jagged 2D array.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    pylist : list\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        Python list to convert to a Java Array.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    java_class : :py:class:`py4j.java_gateway.JavaClass`\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m        Java class to specify the type of Array. Should be in the\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m        form of sc._gateway.jvm.* (sc is a valid Spark Context).\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;124;03m        Example primitive Java classes:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m        - basestring -> sc._gateway.jvm.java.lang.String\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        - int -> sc._gateway.jvm.java.lang.Integer\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        - float -> sc._gateway.jvm.java.lang.Double\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        - bool -> sc._gateway.jvm.java.lang.Boolean\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    :py:class:`py4j.java_collections.JavaArray`\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m      Java Array of converted pylist.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m     99\u001b[0m     java_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m-> 1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/anaconda3/envs/sp/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: savedModel file saved_model.pb not found in folder nlp_flan-t5-small"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "\n",
    "T5 = T5Transformer.loadSavedModel(EXPORT_PATH, spark)\\\n",
    "  .setUseCache(True) \\\n",
    "  .setTask(\"summarize:\") \\\n",
    "  .setMaxOutputLength(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5.write().overwrite().save(f\"{MODEL_NAME}_spark_nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {EXPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "test_data = spark.createDataFrame([\n",
    "    [\"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a \" +\n",
    "       \"downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness\" +\n",
    "       \" of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this \" +\n",
    "       \"paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework \" +\n",
    "       \"that converts all text-based language problems into a text-to-text format. Our systematic study compares \" +\n",
    "       \"pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens \" +\n",
    "       \"of language understanding tasks. By combining the insights from our exploration with scale and our new \" +\n",
    "       \"Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering \" +\n",
    "       \"summarization, question answering, text classification, and more. To facilitate future work on transfer \" +\n",
    "       \"learning for NLP, we release our data set, pre-trained models, and code.\"]\n",
    "]).toDF(\"text\")\n",
    "\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "T5 = T5Transformer.load(f\"{MODEL_NAME}_spark_nlp\") \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"summary\")\n",
    "\n",
    "pipeline = Pipeline().setStages([document_assembler, T5])\n",
    "\n",
    "result = pipeline.fit(test_data).transform(test_data)\n",
    "result.select(\"summary.result\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
