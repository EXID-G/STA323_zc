{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450fbf36-b313-45b4-b634-85834a9a3112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "MODEL_NAME = \"results/checkpoint-3000\"\n",
    "EXPORT_PATH = f\"onnx_models/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd0d1ab-1240-4c3c-8ad4-a25845fd8c47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Framework not specified. Using pt to export the model.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "***** Exporting submodel 1/3: T5Stack *****\n",
      "Using framework PyTorch: 2.3.0+cu121\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "\n",
      "***** Exporting submodel 2/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cu121\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:873: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
      "\n",
      "***** Exporting submodel 3/3: T5ForConditionalGeneration *****\n",
      "Using framework PyTorch: 2.3.0+cu121\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/root/anaconda3/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:508: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "Post-processing the exported models...\n",
      "Deduplicating shared (tied) weights...\n",
      "Could not find ONNX initializer for torch parameter decoder.embed_tokens.weight. decoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Could not find ONNX initializer for torch parameter encoder.embed_tokens.weight. encoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tdecoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tencoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tshared.weight: {'shared.weight'}\n",
      "Could not find ONNX initializer for torch parameter decoder.embed_tokens.weight. decoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Could not find ONNX initializer for torch parameter encoder.embed_tokens.weight. encoder.embed_tokens.weight will not be checked for deduplication.\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tdecoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tencoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
      "\tshared.weight: {'shared.weight'}\n",
      "The two models proto have different outputs (33 and 17 outputs). Constant outputs will be added to unify the two models outputs. This is expected for encoder-decoder models where cached cross-attention key/values are constant outputs, omitted in the model with KV cache.\n",
      "Adding a constant output for present.0.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.0.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.1.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.2.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.3.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.4.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.5.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.6.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.key of shape [0, 6, 1, 64] in model2.\n",
      "Adding a constant output for present.7.encoder.value of shape [0, 6, 1, 64] in model2.\n",
      "\n",
      "Validating ONNX model onnx_models/results/checkpoint-3000/encoder_model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (2, 16, 512) matches (2, 16, 512)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model onnx_models/results/checkpoint-3000/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.3.encoder.key, present.5.decoder.value, present.6.encoder.value, present.4.decoder.value, present.3.decoder.key, present.1.decoder.key, present.1.decoder.value, present.6.decoder.key, present.7.decoder.key, present.0.decoder.value, present.4.encoder.value, present.2.encoder.key, present.5.decoder.key, present.4.encoder.key, present.2.encoder.value, present.0.encoder.key, present.3.decoder.value, present.6.encoder.key, present.0.encoder.value, present.7.encoder.value, present.7.encoder.key, present.0.decoder.key, present.5.encoder.value, present.4.decoder.key, logits, present.6.decoder.value, present.3.encoder.value, present.7.decoder.value, present.2.decoder.key, present.5.encoder.key, present.1.encoder.value, present.2.decoder.value, present.1.encoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 16, 32128) matches (2, 16, 32128)\n",
      "\t\t-[x] values not close enough, max diff: 5.054473876953125e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 1.33514404296875e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.002716064453125e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.86102294921875e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.47955322265625e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[x] values not close enough, max diff: 2.574920654296875e-05 (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.key\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.encoder.value\":\n",
      "\t\t-[✓] (2, 6, 16, 64) matches (2, 6, 16, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\n",
      "Validating ONNX model onnx_models/results/checkpoint-3000/decoder_model_merged.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (present.0.decoder.key, present.4.decoder.value, present.3.decoder.key, present.4.decoder.key, logits, present.1.decoder.key, present.6.decoder.value, present.3.decoder.value, present.1.decoder.value, present.6.decoder.key, present.5.decoder.value, present.7.decoder.key, present.7.decoder.value, present.0.decoder.value, present.2.decoder.key, present.2.decoder.value, present.5.decoder.key)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 1, 32128) matches (2, 1, 32128)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.6.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.key\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"present.7.decoder.value\":\n",
      "\t\t-[✓] (2, 6, 17, 64) matches (2, 6, 17, 64)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 1e-05:\n",
      "- logits: max diff = 5.054473876953125e-05\n",
      "- present.3.decoder.value: max diff = 1.33514404296875e-05\n",
      "- present.4.decoder.value: max diff = 2.002716064453125e-05\n",
      "- present.5.decoder.value: max diff = 2.86102294921875e-05\n",
      "- present.6.decoder.value: max diff = 2.47955322265625e-05\n",
      "- present.7.decoder.value: max diff = 2.574920654296875e-05.\n",
      " The exported model was saved at: onnx_models/results/checkpoint-3000\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export onnx --task text2text-generation-with-past --model {MODEL_NAME} {EXPORT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c000b3-34c2-4770-8f8d-5a824dfa0377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p {EXPORT_PATH}/assets\n",
    "! mv -t {EXPORT_PATH}/assets {EXPORT_PATH}/spiece.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05387e3c-6e1d-4726-b84c-87a511670e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4472f1b4-5cc5-47cb-8901-7b83e47640ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /root/anaconda3/lib/python3.11/site-packages (3.2.3)\n",
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Obtaining dependency information for py4j==0.10.9.7 from https://files.pythonhosted.org/packages/10/30/a58b32568f1623aaad7db22aa9eafc4c6c194b429ff35bdc55ca2726da47/py4j-0.10.9.7-py2.py3-none-any.whl.metadata\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.5\n",
      "    Uninstalling py4j-0.10.9.5:\n",
      "      Successfully uninstalled py4j-0.10.9.5\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.2.3\n",
      "    Uninstalling pyspark-3.2.3:\n",
      "      Successfully uninstalled pyspark-3.2.3\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spark-nlp in /root/anaconda3/lib/python3.11/site-packages (5.3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyspark\n",
    "!pip install --upgrade spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e82d919-aa3e-42d4-9bb1-f068ea520a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/module/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-83d21c82-4663-4cd7-9511-4b5465c99eca;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      ":: resolution report :: resolve 1776ms :: artifacts dl 33ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   83  |   0   |   0   |   5   ||   78  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-83d21c82-4663-4cd7-9511-4b5465c99eca\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 78 already retrieved (0kB/58ms)\n",
      "24/06/03 14:18:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6618fba-d985-4ca1-866f-879d6c8dab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPUs\n",
      "Using CPUs\n",
      "Using CPUs\n",
      "Using CPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the foundation for separation results within complexity classes?\n",
      "Answer: a reversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is responsible for constraining P according to the time hierarchy theorem?\n",
      "Answer: a reversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Within what variable is L constrained according to the space hierarchy theorem?\n",
      "Answer: a definite reversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does not form the basis for most separation results of complexity classes?\n",
      "Answer: a time and space hierarchy theorem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does the past time and space hierarchy theorems form the basis of?\n",
      "Answer: the theory of the universe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is not strictly contained in EXPTIME?\n",
      "Answer: a definite reversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is not strictly contained in PSPACE?\n",
      "Answer: a definite reversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What concept is frequently used to define complexity classes?\n",
      "Answer: a reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Reduction essentially takes one problem and converts into what?\n",
      "Answer: a solution\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "import threading\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import T5Transformer\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'SparkNLPKafka',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    ")\n",
    "\n",
    "T5 = T5Transformer.loadSavedModel(EXPORT_PATH, spark)\\\n",
    "  .setUseCache(True) \\\n",
    "  .setTask(\"summarize:\") \\\n",
    "  .setMaxOutputLength(200)\n",
    "T5.write().overwrite().save(f\"{MODEL_NAME}_spark_nlp\")\n",
    "\n",
    "# 创建Spark-NLP模型Pipeline\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "T5 = T5Transformer.load(f\"{MODEL_NAME}_spark_nlp\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"summary\")\n",
    "# 创建管道\n",
    "\n",
    "pipeline = Pipeline().setStages([document_assembler, T5])\n",
    "\n",
    "# 定义处理函数\n",
    "def process_message(message):\n",
    "    question = message['question']\n",
    "    context = message['context']\n",
    "    combined_text = f\"Please answer to this question: {question} Context: {context}\"\n",
    "    return combined_text, question\n",
    "# 创建Kafka消费数据的函数\n",
    "def kafka_streaming():\n",
    "    start_time = time.time()\n",
    "    for msg in consumer:\n",
    "        current_time = time.time()\n",
    "        if current_time - start_time > 20:\n",
    "            break\n",
    "        message = msg.value\n",
    "        combined_text, question = process_message(message)\n",
    "        data = spark.createDataFrame([(Q,)], [\"text\"])\n",
    "        result = pipeline.fit(data).transform(data)\n",
    "        summaries = result.select(\"summary.result\").collect()\n",
    "        for summary in summaries:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {summary['result'][0]}\")\n",
    "# 使用线程运行Kafka消费者\n",
    "thread = threading.Thread(target=kafka_streaming)\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
