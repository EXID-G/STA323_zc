{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "import shutil\n",
    "from ray.tune import CLIReporter\n",
    "\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    T5ForConditionalGeneration,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.torch import TuneReportCallback\n",
    "import ray.train.huggingface.transformers\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型和分词器\n",
    "model_name = \"flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> shanghai</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Where is the capital of China?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `train_func()` ---  Encapsulate data preprocessing, training, and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load & preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples,mytokenizer):\n",
    "    # Ensure inputs and targets are lists of strings\n",
    "    inputs = [str(ex) for ex in examples['input']]\n",
    "    targets = [str(ex) for ex in examples['output']]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = mytokenizer(inputs, max_length=512, truncation=True)\n",
    "    # Tokenize targets\n",
    "    # with tokenizer.as_target_tokenizer():\n",
    "    labels = mytokenizer(targets, max_length=128, truncation=True)\n",
    "    # Add labels to model inputs\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def save_dataset(dataset, path):\n",
    "    # dataset.save_to_disk(path)\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "def load_preprocessed_dataset(path):\n",
    "    # return Dataset.load_from_disk(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "    return tmp\n",
    "\n",
    "def load_and_preprocess_datasets(tokenizer=tokenizer):\n",
    "    train_save_path = 'data/mydata/preprocessed/train.pkl'\n",
    "    val_save_path = 'data/mydata/preprocessed/val.pkl'\n",
    "    test_save_path = 'data/mydata/preprocessed/test.pkl'\n",
    "\n",
    "    if os.path.exists(train_save_path) and os.path.exists(val_save_path) and os.path.exists(test_save_path):\n",
    "        train_dataset = load_preprocessed_dataset(train_save_path)\n",
    "        val_dataset = load_preprocessed_dataset(val_save_path)\n",
    "        test_dataset = load_preprocessed_dataset(test_save_path)\n",
    "    else:\n",
    "        train_dataset = load_dataset('csv', data_files='/spark_zc/STA323_zc/proj2/data/mydata/mytrain.csv', cache_dir='data/cachefile')['train']\n",
    "        val_dataset = load_dataset('csv', data_files='/spark_zc/STA323_zc/proj2/data/mydata/myvalidation.csv', cache_dir='data/cachefile')['train']\n",
    "        test_dataset = load_dataset('csv', data_files='/spark_zc/STA323_zc/proj2/data/mydata/mytest.csv', cache_dir='data/cachefile')['train']\n",
    "\n",
    "        train_dataset = train_dataset.map(lambda examples: preprocess_function(examples, tokenizer), batched=True)\n",
    "        val_dataset = val_dataset.map(lambda examples: preprocess_function(examples, tokenizer), batched=True)\n",
    "        test_dataset = test_dataset.map(lambda examples: preprocess_function(examples, tokenizer), batched=True)\n",
    "\n",
    "        save_dataset(train_dataset, train_save_path)\n",
    "        save_dataset(val_dataset, val_save_path)\n",
    "        save_dataset(test_dataset, test_save_path)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_and_preprocess_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个训练函数，该函数将接收超参数配置并训练模型。注意要使用Ray的对象存储来获取数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Encapsulate data preprocessing, training, and evaluation\n",
    "# logic in a training function\n",
    "# ============================================================\n",
    "\n",
    "def train_func(config):\n",
    "    ###################################* load data\n",
    "    train_dataset, val_dataset, test_dataset = load_and_preprocess_datasets()\n",
    "\n",
    "    ###################################* load model and tokenizer\n",
    "    model_name_path = \"/spark_zc/STA323_zc/proj2/flan-t5-small\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name_path)\n",
    "\n",
    "    ###################################* metrix\n",
    "    def compute_metrics(p):\n",
    "        predictions, labels = p\n",
    "\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "        predictions = predictions.flatten()\n",
    "        labels = labels.flatten()\n",
    "\n",
    "        metric = load_metric(\"accuracy\")\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"/spark_zc/STA323_zc/proj2/results\",\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        per_device_train_batch_size=config[\"batch_size\"],\n",
    "        per_device_eval_batch_size=config[\"batch_size\"],\n",
    "        num_train_epochs=config[\"num_epochs\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        save_total_limit=1,          # 只保留一个checkpoint\n",
    "        load_best_model_at_end=True, # 是否在训练结束时加载最佳模型\n",
    "        metric_for_best_model=\"eval_loss\", # 选择最佳模型的指标\n",
    "        greater_is_better=False,  # 表示更小的评估损失表示更好的模型\n",
    "        save_strategy=\"epoch\",  # 表示每个训练周期结束后保存模型\n",
    "        evaluation_strategy=\"epoch\", # 每个训练周期结束后评估模型\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[ray.train.huggingface.transformers.RayTrainReportCallback()],\n",
    "    )\n",
    "\n",
    "    trainer = ray.train.huggingface.transformers.prepare_trainer(trainer)\n",
    "    trainer.train()\n",
    "\n",
    "    # # Save the trained model checkpoint\n",
    "    # with tune.checkpoint_dir(step=trainer.state.global_step) as checkpoint_dir:\n",
    "    #     model.save_pretrained(checkpoint_dir)\n",
    "    #     tokenizer.save_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error `FileNotFoundError: Unable to find '/tmp/ray/session_2024-06-03_23-57-28_281310_151578/artifacts/2024-06-04_00-03-46/TorchTrainer_2024-06-04_00-03-46/working_dirs/TorchTrainer_dba0f_00000_0_2024-06-04_00-03-46/data/mydata/mytrain.csv'` is the direct cause of failure, hence I substitue the relative path with the absolute path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [4] Define a Ray TorchTrainer to launch `train_func` on all workers\n",
    "# # ===================================================================\n",
    "# ray_trainer = TorchTrainer(\n",
    "#     train_func,\n",
    "#     scaling_config=ScalingConfig(num_workers=1, use_gpu=False),\n",
    "#     # [4a] If running in a multi-node cluster, this is where you\n",
    "#     # should configure the run's persistent storage that is accessible\n",
    "#     # across all worker nodes.\n",
    "#     # run_config=ray.train.RunConfig(\n",
    "#     #     failure_config=ray.train.FailureConfig(max_failures = -1)\n",
    "#     #     )\n",
    "# )\n",
    "# result: ray.train.Result = ray_trainer.fit()\n",
    "\n",
    "# # [5] Load the trained model.\n",
    "# with result.checkpoint.as_directory() as checkpoint_dir:\n",
    "#     checkpoint_path = os.path.join(\n",
    "#         checkpoint_dir,\n",
    "#         ray.train.huggingface.transformers.RayTrainReportCallback.CHECKPOINT_NAME,\n",
    "#     )\n",
    "#     model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.metrics     # The metrics reported during training.\n",
    "# result.checkpoint  # The latest checkpoint reported during training.\n",
    "# result.path        # The path where logs are stored.\n",
    "# result.error       # The exception that was raised, if training failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space and init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化Ray，并定义调度器以控制试验的调度策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scheduler = tune.schedulers.ASHAScheduler(\n",
    "    metric=\"eval_accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_transformer():\n",
    "    search_space = {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-3),\n",
    "        \"batch_size\": tune.choice([8, 16, 32]),\n",
    "        \"num_epochs\": tune.choice([1]),\n",
    "        # \"num_epochs\": tune.choice([2, 3, 4]),\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "    }\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"learning_rate\", \"num_train_epochs\", \"weight_decay\"],\n",
    "        metric_columns=[\"eval_accuracy\", \"eval_loss\", \"epoch\", \"training_iteration\"],\n",
    "        max_report_frequency=10,  # 控制报告频率\n",
    "        print_intermediate_tables=False  # 关闭中间表格输出\n",
    "    )\n",
    "    analysis = tune.run(\n",
    "        train_func,\n",
    "        resources_per_trial={\"cpu\": 0.2},  # Adjust as needed\n",
    "        config=search_space,\n",
    "        num_samples=1,  # Number of trials\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        name=\"tune_qa_model\",\n",
    "        local_dir=\"/spark_zc/STA323_zc/proj2/ray_results\",\n",
    "        stop={\"training_iteration\": 2},\n",
    "        keep_checkpoints_num=3,  # 限制保存的 checkpoint 数量\n",
    "        checkpoint_score_attr=\"eval_acc\",  # 根据验证集的准确率选择保留的 checkpoint\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    best_trial = analysis.get_best_trial(metric=\"eval_loss\", mode=\"min\")\n",
    "    best_model_path = best_trial.checkpoint.value\n",
    "    # 创建目标文件夹路径\n",
    "    destination_path = \"/path/to/bestmodel\"\n",
    "    # 复制整个目录\n",
    "    shutil.copytree(best_model_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 02:38:05,081\tWARNING services.py:2009 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66101248 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=7.89gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-06-04 02:38:06,282\tINFO worker.py:1740 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/root/anaconda3/lib/python3.11/site-packages/ray/tune/tune.py:583: UserWarning: The `local_dir` argument is deprecated and will be removed. This will pass-through to set the `storage_path` for now but will raise an error in the future. You should only set the `storage_path` from now on.\n",
      "  warnings.warn(\n",
      "2024-06-04 02:38:46,079\tINFO tune.py:614 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:38:46 (running for 00:00:00.27)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=336911)\u001b[0m /root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "\u001b[36m(pid=336911)\u001b[0m   torch.utils._pytree._register_pytree_node(\n",
      "\u001b[36m(pid=336911)\u001b[0m /root/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "\u001b[36m(pid=336911)\u001b[0m   torch.utils._pytree._register_pytree_node(\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 10000 examples [00:00, 41070.70 examples/s]\n",
      "Generating train split: 20000 examples [00:00, 45172.39 examples/s]\n",
      "Generating train split: 30000 examples [00:00, 50480.11 examples/s]\n",
      "Generating train split: 40000 examples [00:00, 52764.39 examples/s]\n",
      "Generating train split: 50000 examples [00:00, 53214.78 examples/s]\n",
      "Generating train split: 60000 examples [00:01, 51209.02 examples/s]\n",
      "Generating train split: 70000 examples [00:01, 50229.60 examples/s]\n",
      "Generating train split: 81819 examples [00:01, 51001.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:38:56 (running for 00:00:10.37)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 5000 examples [00:00, 51092.97 examples/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 10000 examples [00:00, 73774.41 examples/s]\n",
      "Generating train split: 20302 examples [00:00, 60754.44 examples/s]\n",
      "Map:   0%|          | 0/81819 [00:00<?, ? examples/s]\n",
      "Map:   1%|          | 1000/81819 [00:01<01:21, 994.05 examples/s]\n",
      "Map:   2%|▏         | 2000/81819 [00:02<01:22, 965.57 examples/s]\n",
      "Map:   4%|▎         | 3000/81819 [00:03<01:21, 969.32 examples/s]\n",
      "Map:   5%|▍         | 4000/81819 [00:04<01:38, 792.60 examples/s]\n",
      "Map:   6%|▌         | 5000/81819 [00:05<01:33, 825.76 examples/s]\n",
      "Map:   7%|▋         | 6000/81819 [00:06<01:27, 870.22 examples/s]\n",
      "Map:   9%|▊         | 7000/81819 [00:07<01:24, 887.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:06 (running for 00:00:20.41)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  10%|▉         | 8000/81819 [00:08<01:19, 933.28 examples/s]\n",
      "Map:  11%|█         | 9000/81819 [00:10<01:24, 862.51 examples/s]\n",
      "Map:  12%|█▏        | 10000/81819 [00:11<01:19, 902.74 examples/s]\n",
      "Map:  13%|█▎        | 11000/81819 [00:12<01:16, 930.51 examples/s]\n",
      "Map:  15%|█▍        | 12000/81819 [00:13<01:13, 949.43 examples/s]\n",
      "Map:  16%|█▌        | 13000/81819 [00:14<01:10, 976.55 examples/s]\n",
      "Map:  17%|█▋        | 14000/81819 [00:15<01:18, 867.81 examples/s]\n",
      "Map:  18%|█▊        | 15000/81819 [00:16<01:15, 888.73 examples/s]\n",
      "Map:  20%|█▉        | 16000/81819 [00:17<01:12, 913.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:16 (running for 00:00:30.44)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  21%|██        | 17000/81819 [00:18<01:08, 942.10 examples/s]\n",
      "Map:  22%|██▏       | 18000/81819 [00:19<01:06, 959.55 examples/s]\n",
      "Map:  23%|██▎       | 19000/81819 [00:21<01:12, 866.57 examples/s]\n",
      "Map:  24%|██▍       | 20000/81819 [00:22<01:15, 822.66 examples/s]\n",
      "Map:  26%|██▌       | 21000/81819 [00:23<01:09, 874.68 examples/s]\n",
      "Map:  27%|██▋       | 22000/81819 [00:24<01:04, 921.19 examples/s]\n",
      "Map:  28%|██▊       | 23000/81819 [00:25<01:09, 843.08 examples/s]\n",
      "Map:  29%|██▉       | 24000/81819 [00:26<01:06, 871.16 examples/s]\n",
      "Map:  31%|███       | 25000/81819 [00:27<01:02, 905.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:26 (running for 00:00:40.48)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  32%|███▏      | 26000/81819 [00:28<00:59, 943.55 examples/s]\n",
      "Map:  33%|███▎      | 27000/81819 [00:29<00:56, 967.08 examples/s]\n",
      "Map:  34%|███▍      | 28000/81819 [00:31<01:01, 870.01 examples/s]\n",
      "Map:  35%|███▌      | 29000/81819 [00:32<00:58, 895.34 examples/s]\n",
      "Map:  37%|███▋      | 30000/81819 [00:33<00:56, 917.21 examples/s]\n",
      "Map:  38%|███▊      | 31000/81819 [00:34<00:53, 949.79 examples/s]\n",
      "Map:  39%|███▉      | 32000/81819 [00:35<00:53, 939.49 examples/s]\n",
      "Map:  40%|████      | 33000/81819 [00:36<00:58, 839.89 examples/s]\n",
      "Map:  42%|████▏     | 34000/81819 [00:37<00:54, 873.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:36 (running for 00:00:50.51)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  43%|████▎     | 35000/81819 [00:38<00:50, 922.72 examples/s]\n",
      "Map:  44%|████▍     | 36000/81819 [00:40<00:51, 887.29 examples/s]\n",
      "Map:  45%|████▌     | 37000/81819 [00:41<00:48, 916.87 examples/s]\n",
      "Map:  46%|████▋     | 38000/81819 [00:42<00:51, 854.19 examples/s]\n",
      "Map:  48%|████▊     | 39000/81819 [00:43<00:47, 902.10 examples/s]\n",
      "Map:  49%|████▉     | 40000/81819 [00:44<00:44, 946.03 examples/s]\n",
      "Map:  50%|█████     | 41000/81819 [00:45<00:42, 958.00 examples/s]\n",
      "Map:  51%|█████▏    | 42000/81819 [00:46<00:42, 935.86 examples/s]\n",
      "Map:  53%|█████▎    | 43000/81819 [00:48<00:47, 822.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:46 (running for 00:01:00.54)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  54%|█████▍    | 44000/81819 [00:49<00:44, 851.68 examples/s]\n",
      "Map:  55%|█████▍    | 45000/81819 [00:50<00:41, 877.58 examples/s]\n",
      "Map:  56%|█████▌    | 46000/81819 [00:51<00:41, 872.17 examples/s]\n",
      "Map:  57%|█████▋    | 47000/81819 [00:52<00:44, 783.87 examples/s]\n",
      "Map:  59%|█████▊    | 48000/81819 [00:53<00:40, 831.25 examples/s]\n",
      "Map:  60%|█████▉    | 49000/81819 [00:55<00:38, 845.06 examples/s]\n",
      "Map:  61%|██████    | 50000/81819 [00:56<00:42, 746.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:39:56 (running for 00:01:10.57)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  62%|██████▏   | 51000/81819 [00:58<00:43, 703.35 examples/s]\n",
      "Map:  64%|██████▎   | 52000/81819 [00:59<00:39, 755.45 examples/s]\n",
      "Map:  65%|██████▍   | 53000/81819 [01:00<00:35, 804.17 examples/s]\n",
      "Map:  66%|██████▌   | 54000/81819 [01:01<00:33, 825.35 examples/s]\n",
      "Map:  67%|██████▋   | 55000/81819 [01:02<00:30, 868.01 examples/s]\n",
      "Map:  68%|██████▊   | 56000/81819 [01:04<00:31, 832.01 examples/s]\n",
      "Map:  70%|██████▉   | 57000/81819 [01:05<00:28, 876.79 examples/s]\n",
      "Map:  71%|███████   | 58000/81819 [01:06<00:26, 891.81 examples/s]\n",
      "Map:  72%|███████▏  | 59000/81819 [01:07<00:24, 918.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:06 (running for 00:01:20.60)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  73%|███████▎  | 60000/81819 [01:08<00:25, 845.43 examples/s]\n",
      "Map:  75%|███████▍  | 61000/81819 [01:09<00:23, 902.45 examples/s]\n",
      "Map:  76%|███████▌  | 62000/81819 [01:10<00:20, 950.75 examples/s]\n",
      "Map:  77%|███████▋  | 63000/81819 [01:11<00:21, 891.12 examples/s]\n",
      "Map:  78%|███████▊  | 64000/81819 [01:12<00:19, 930.38 examples/s]\n",
      "Map:  79%|███████▉  | 65000/81819 [01:13<00:19, 879.14 examples/s]\n",
      "Map:  81%|████████  | 66000/81819 [01:14<00:16, 931.39 examples/s]\n",
      "Map:  82%|████████▏ | 67000/81819 [01:15<00:15, 950.04 examples/s]\n",
      "Map:  83%|████████▎ | 68000/81819 [01:16<00:14, 938.59 examples/s]\n",
      "Map:  84%|████████▍ | 69000/81819 [01:17<00:13, 952.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:16 (running for 00:01:30.63)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  86%|████████▌ | 70000/81819 [01:19<00:13, 893.62 examples/s]\n",
      "Map:  87%|████████▋ | 71000/81819 [01:20<00:11, 930.91 examples/s]\n",
      "Map:  88%|████████▊ | 72000/81819 [01:21<00:10, 932.11 examples/s]\n",
      "Map:  89%|████████▉ | 73000/81819 [01:22<00:09, 941.04 examples/s]\n",
      "Map:  90%|█████████ | 74000/81819 [01:23<00:08, 963.60 examples/s]\n",
      "Map:  92%|█████████▏| 75000/81819 [01:24<00:07, 903.76 examples/s]\n",
      "Map:  93%|█████████▎| 76000/81819 [01:25<00:06, 943.43 examples/s]\n",
      "Map:  94%|█████████▍| 77000/81819 [01:26<00:05, 860.31 examples/s]\n",
      "Map:  95%|█████████▌| 78000/81819 [01:27<00:04, 898.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:26 (running for 00:01:40.67)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  97%|█████████▋| 79000/81819 [01:28<00:03, 934.90 examples/s]\n",
      "Map:  98%|█████████▊| 80000/81819 [01:30<00:02, 882.22 examples/s]\n",
      "Map:  99%|█████████▉| 81000/81819 [01:31<00:00, 936.53 examples/s]\n",
      "Map: 100%|██████████| 81819/81819 [01:31<00:00, 889.75 examples/s]\n",
      "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]\n",
      "Map:  20%|██        | 1000/5000 [00:00<00:03, 1062.61 examples/s]\n",
      "Map:  40%|████      | 2000/5000 [00:01<00:02, 1047.45 examples/s]\n",
      "Map:  60%|██████    | 3000/5000 [00:02<00:01, 1065.55 examples/s]\n",
      "Map:  80%|████████  | 4000/5000 [00:04<00:01, 916.40 examples/s] \n",
      "Map: 100%|██████████| 5000/5000 [00:05<00:00, 952.03 examples/s]\n",
      "Map:   0%|          | 0/20302 [00:00<?, ? examples/s]\n",
      "Map:   5%|▍         | 1000/20302 [00:00<00:15, 1255.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:36 (running for 00:01:50.69)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  10%|▉         | 2000/20302 [00:01<00:13, 1321.43 examples/s]\n",
      "Map:  15%|█▍        | 3000/20302 [00:02<00:15, 1107.83 examples/s]\n",
      "Map:  20%|█▉        | 4000/20302 [00:03<00:16, 1002.25 examples/s]\n",
      "Map:  25%|██▍       | 5000/20302 [00:04<00:15, 1015.42 examples/s]\n",
      "Map:  30%|██▉       | 6000/20302 [00:06<00:16, 861.88 examples/s] \n",
      "Map:  34%|███▍      | 7000/20302 [00:07<00:14, 933.12 examples/s]\n",
      "Map:  39%|███▉      | 8000/20302 [00:08<00:12, 977.24 examples/s]\n",
      "Map:  44%|████▍     | 9000/20302 [00:09<00:12, 886.75 examples/s]\n",
      "Map:  49%|████▉     | 10000/20302 [00:10<00:11, 899.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:46 (running for 00:02:00.72)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  54%|█████▍    | 11000/20302 [00:11<00:09, 949.06 examples/s]\n",
      "Map:  59%|█████▉    | 12000/20302 [00:12<00:08, 993.69 examples/s]\n",
      "Map:  64%|██████▍   | 13000/20302 [00:13<00:07, 988.68 examples/s]\n",
      "Map:  69%|██████▉   | 14000/20302 [00:14<00:07, 893.47 examples/s]\n",
      "Map:  74%|███████▍  | 15000/20302 [00:15<00:05, 964.65 examples/s]\n",
      "Map:  79%|███████▉  | 16000/20302 [00:16<00:04, 1020.37 examples/s]\n",
      "Map:  84%|████████▎ | 17000/20302 [00:17<00:03, 983.90 examples/s] \n",
      "Map:  89%|████████▊ | 18000/20302 [00:18<00:02, 999.31 examples/s]\n",
      "Map:  94%|█████████▎| 19000/20302 [00:19<00:01, 916.56 examples/s]\n",
      "Map:  99%|█████████▊| 20000/20302 [00:20<00:00, 942.27 examples/s]\n",
      "Map: 100%|██████████| 20302/20302 [00:21<00:00, 966.67 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:40:56 (running for 00:02:10.75)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_func pid=336911)\u001b[0m /root/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "\u001b[36m(train_func pid=336911)\u001b[0m dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "\u001b[36m(train_func pid=336911)\u001b[0m   warnings.warn(\n",
      "  0%|          | 0/2557 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:06 (running for 00:02:20.78)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:16 (running for 00:02:30.80)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:26 (running for 00:02:40.83)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:36 (running for 00:02:50.86)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:46 (running for 00:03:00.88)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2557 [00:49<35:17:59, 49.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:41:57 (running for 00:03:10.91)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:07 (running for 00:03:20.94)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:17 (running for 00:03:30.95)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:27 (running for 00:03:40.98)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:37 (running for 00:03:51.01)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2557 [01:45<37:55:58, 53.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:47 (running for 00:04:01.05)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:42:57 (running for 00:04:11.09)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:07 (running for 00:04:21.12)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:17 (running for 00:04:31.15)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:27 (running for 00:04:41.18)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2557 [02:33<35:57:53, 50.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:37 (running for 00:04:51.21)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:47 (running for 00:05:01.23)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:43:57 (running for 00:05:11.27)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:07 (running for 00:05:21.29)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:17 (running for 00:05:31.32)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:27 (running for 00:05:41.35)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2557 [03:36<39:24:51, 55.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:37 (running for 00:05:51.38)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:47 (running for 00:06:01.41)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:44:57 (running for 00:06:11.44)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:07 (running for 00:06:21.48)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2557 [04:12<34:20:24, 48.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:17 (running for 00:06:31.61)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:27 (running for 00:06:41.64)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:37 (running for 00:06:51.66)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:47 (running for 00:07:01.70)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2557 [04:54<32:56:59, 46.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:45:57 (running for 00:07:11.73)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:07 (running for 00:07:21.76)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:17 (running for 00:07:31.78)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:27 (running for 00:07:41.81)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:37 (running for 00:07:51.85)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:48 (running for 00:08:01.88)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2557 [05:50<35:00:09, 49.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:46:58 (running for 00:08:11.91)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:08 (running for 00:08:21.96)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:18 (running for 00:08:31.99)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:28 (running for 00:08:42.01)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:38 (running for 00:08:52.03)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:48 (running for 00:09:02.06)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:47:58 (running for 00:09:12.16)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2557 [06:59<39:33:23, 55.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:08 (running for 00:09:22.19)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:18 (running for 00:09:32.22)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:28 (running for 00:09:42.25)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:38 (running for 00:09:52.27)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:48 (running for 00:10:02.30)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:48:58 (running for 00:10:12.33)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:08 (running for 00:10:22.35)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2557 [08:12<43:20:37, 61.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:18 (running for 00:10:32.37)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:28 (running for 00:10:42.40)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:38 (running for 00:10:52.42)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:48 (running for 00:11:02.52)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:49:58 (running for 00:11:12.54)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:08 (running for 00:11:22.57)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:18 (running for 00:11:32.60)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2557 [09:25<45:53:37, 64.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:28 (running for 00:11:42.62)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:38 (running for 00:11:52.64)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:48 (running for 00:12:02.67)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:50:58 (running for 00:12:12.70)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:08 (running for 00:12:22.72)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:18 (running for 00:12:32.76)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:28 (running for 00:12:42.79)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:38 (running for 00:12:52.81)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2557 [10:40<48:03:08, 67.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:48 (running for 00:13:02.83)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:51:58 (running for 00:13:12.86)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:08 (running for 00:13:22.88)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:19 (running for 00:13:32.90)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2557 [11:21<42:05:54, 59.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:29 (running for 00:13:43.00)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:39 (running for 00:13:53.02)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:49 (running for 00:14:03.05)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:52:59 (running for 00:14:13.07)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:09 (running for 00:14:23.10)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2557 [12:20<42:00:27, 59.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:19 (running for 00:14:33.13)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:29 (running for 00:14:43.15)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:39 (running for 00:14:53.17)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:49 (running for 00:15:03.20)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:53:59 (running for 00:15:13.23)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:09 (running for 00:15:23.25)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2557 [13:14<40:45:42, 57.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:19 (running for 00:15:33.27)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:29 (running for 00:15:43.29)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:39 (running for 00:15:53.32)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:49 (running for 00:16:03.34)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2557 [13:59<38:13:13, 54.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:54:59 (running for 00:16:13.37)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:09 (running for 00:16:23.39)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:19 (running for 00:16:33.42)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:29 (running for 00:16:43.44)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:39 (running for 00:16:53.47)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2557 [14:42<35:46:35, 50.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:49 (running for 00:17:03.54)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:55:59 (running for 00:17:13.63)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:56:09 (running for 00:17:23.72)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:56:19 (running for 00:17:33.82)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2557 [15:23<33:42:34, 47.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:56:30 (running for 00:17:43.89)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:56:40 (running for 00:17:53.99)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:56:50 (running for 00:18:04.04)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:57:00 (running for 00:18:14.09)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:57:10 (running for 00:18:24.12)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2557 [16:17<35:02:22, 49.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-06-04 02:57:20 (running for 00:18:34.24)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:57:30 (running for 00:18:44.34)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-06-04 02:57:40 (running for 00:18:54.37)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0.2/128 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-06-04_02-38-03_004700_328376/artifacts/2024-06-04_02-38-46/tune_qa_model/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.17.0.13, ID: cc6410da2eb894759e0b9d534b66d9fe489099b538bc5897caac4e0d) where the task (actor ID: 996e88f353f9e77e16c7982b01000000, name=ImplicitFunc.__init__, pid=336911, memory used=16.02GB) was running was 30.45GB / 32.00GB (0.951603), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.0.13`. To see the logs of the worker, use `ray logs worker-06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887*out -ip 172.17.0.13. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n336911\t16.02\tray::ImplicitFunc.train\n127410\t2.46\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /r...\n279474\t1.08\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n56\t0.89\t/opt/module/jdk_1.8/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:Initiati...\n328376\t0.82\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n127144\t0.76\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node --...\n328407\t0.57\t/root/anaconda3/lib/python3.11/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/sess...\n27\t0.20\t/opt/module/jdk_1.8/bin/java -Dzookeeper.log.dir=/opt/module/zookeeper/apache-zookeeper-3.8.3-bin/bi...\n6159\t0.15\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /d...\n10\t0.12\t/root/anaconda3/bin/python /root/anaconda3/bin/jupyter-lab --port=8888 --ip 0.0.0.0 --no-browser --a...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py:110\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     result \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(future)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:2623\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2623\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m worker\u001b[38;5;241m.\u001b[39mget_objects(object_refs, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:863\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 863\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values, debugger_breakpoint\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.17.0.13, ID: cc6410da2eb894759e0b9d534b66d9fe489099b538bc5897caac4e0d) where the task (actor ID: 996e88f353f9e77e16c7982b01000000, name=ImplicitFunc.__init__, pid=336911, memory used=16.02GB) was running was 30.45GB / 32.00GB (0.951603), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.0.13`. To see the logs of the worker, use `ray logs worker-06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887*out -ip 172.17.0.13. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n336911\t16.02\tray::ImplicitFunc.train\n127410\t2.46\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /r...\n279474\t1.08\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n56\t0.89\t/opt/module/jdk_1.8/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:Initiati...\n328376\t0.82\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n127144\t0.76\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node --...\n328407\t0.57\t/root/anaconda3/lib/python3.11/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/sess...\n27\t0.20\t/opt/module/jdk_1.8/bin/java -Dzookeeper.log.dir=/opt/module/zookeeper/apache-zookeeper-3.8.3-bin/bi...\n6159\t0.15\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /d...\n10\t0.12\t/root/anaconda3/bin/python /root/anaconda3/bin/jupyter-lab --port=8888 --ip 0.0.0.0 --no-browser --a...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ray\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m      3\u001b[0m ray\u001b[38;5;241m.\u001b[39minit(ignore_reinit_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m tune_transformer()\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtune_transformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m search_space \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m reporter \u001b[38;5;241m=\u001b[39m CLIReporter(\n\u001b[1;32m     11\u001b[0m     parameter_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_train_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m     metric_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m     max_report_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# 控制报告频率\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     print_intermediate_tables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# 关闭中间表格输出\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m analysis \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     17\u001b[0m     train_func,\n\u001b[1;32m     18\u001b[0m     resources_per_trial\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.2\u001b[39m},  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     config\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m     20\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Number of trials\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m     22\u001b[0m     progress_reporter\u001b[38;5;241m=\u001b[39mreporter,\n\u001b[1;32m     23\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtune_qa_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     local_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/spark_zc/STA323_zc/proj2/ray_results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     stop\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m},\n\u001b[1;32m     26\u001b[0m     keep_checkpoints_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# 限制保存的 checkpoint 数量\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     checkpoint_score_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 根据验证集的准确率选择保留的 checkpoint\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found were: \u001b[39m\u001b[38;5;124m\"\u001b[39m, analysis\u001b[38;5;241m.\u001b[39mbest_config)\n\u001b[1;32m     31\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_trial(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/tune/tune.py:992\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 992\u001b[0m         runner\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[1;32m    994\u001b[0m             _report_progress(runner, progress_reporter)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:685\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_add_actors()\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnext(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_resources_manager\u001b[38;5;241m.\u001b[39mon_no_available_trials(\n\u001b[1;32m    690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_trials()\n\u001b[1;32m    691\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:223\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_state_events\u001b[38;5;241m.\u001b[39mresolve_future(future)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m actor_task_futures:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_task_events\u001b[38;5;241m.\u001b[39mresolve_future(future)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_ready_resource_future()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py:113\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_error:\n\u001b[0;32m--> 113\u001b[0m         on_error(e)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:771\u001b[0m, in \u001b[0;36mRayActorManager._schedule_tracked_actor_task.<locals>.on_error\u001b[0;34m(exception)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_error\u001b[39m(exception: \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_task_failed(\n\u001b[1;32m    772\u001b[0m         tracked_actor_task\u001b[38;5;241m=\u001b[39mtracked_actor_task, exception\u001b[38;5;241m=\u001b[39mexception\n\u001b[1;32m    773\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:290\u001b[0m, in \u001b[0;36mRayActorManager._actor_task_failed\u001b[0;34m(self, tracked_actor_task, exception)\u001b[0m\n\u001b[1;32m    288\u001b[0m         tracked_actor_task\u001b[38;5;241m.\u001b[39m_on_error(tracked_actor, exception)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaught unexpected exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.17.0.13, ID: cc6410da2eb894759e0b9d534b66d9fe489099b538bc5897caac4e0d) where the task (actor ID: 996e88f353f9e77e16c7982b01000000, name=ImplicitFunc.__init__, pid=336911, memory used=16.02GB) was running was 30.45GB / 32.00GB (0.951603), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.0.13`. To see the logs of the worker, use `ray logs worker-06fb3109625fbd86a41e6133fca054b69b0862aa511990a32b1d5887*out -ip 172.17.0.13. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n336911\t16.02\tray::ImplicitFunc.train\n127410\t2.46\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /r...\n279474\t1.08\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n56\t0.89\t/opt/module/jdk_1.8/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:Initiati...\n328376\t0.82\t/root/anaconda3/bin/python -m ipykernel_launcher --f=/root/.local/share/jupyter/runtime/kernel-v2-12...\n127144\t0.76\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node --...\n328407\t0.57\t/root/anaconda3/lib/python3.11/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/sess...\n27\t0.20\t/opt/module/jdk_1.8/bin/java -Dzookeeper.log.dir=/opt/module/zookeeper/apache-zookeeper-3.8.3-bin/bi...\n6159\t0.15\t/data/root/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node /d...\n10\t0.12\t/root/anaconda3/bin/python /root/anaconda3/bin/jupyter-lab --port=8888 --ip 0.0.0.0 --no-browser --a...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-04 02:58:06,198 E 328649 328649] (raylet) node_manager.cc:3041: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: cc6410da2eb894759e0b9d534b66d9fe489099b538bc5897caac4e0d, IP: 172.17.0.13) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.13`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "# Run Ray Tune\n",
    "# ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)\n",
    "tune_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "# best_trial = analysis.get_best_trial(\"eval_loss\", \"min\", \"last\")\n",
    "# best_checkpoint_dir = analysis.get_best_checkpoint(best_trial)\n",
    "# model.save_pretrained(best_checkpoint_dir)\n",
    "# tokenizer.save_pretrained(best_checkpoint_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
