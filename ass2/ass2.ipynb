{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "# from pyspark.sql.types import StringType, StructType, StructField\n",
    "from pyspark.sql.types import *\n",
    "# import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/09 12:00:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.ui.port', 64050).appName(\"ass2_Q1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|value                                                       |\n",
      "+------------------------------------------------------------+\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|\n",
      "|KKEVVAVAKKEEVLKKEVVVPSKKDEEILPLKKEVPRPPKKEEDVMPQKKEVPRPPKKEE|\n",
      "|DIVPQMRDVSLPPKEEEKIVPKKKEVPRPPKKVEEILPPKKEVHRPPKKEEDIVPQIREV|\n",
      "|SLPPKKDEEIVCEKKEVAPAKEEPSKKPKVPSLPATQREDVIEEIIHKKPTAALSKFEDV|\n",
      "|KEHEEKETFVVLKKEIIDAPTKKEMVTAKHVIVPQKEEIIPSPTQEEVVSFKRKQTVRTS|\n",
      "+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_1 = spark.read.text(\"data/Q1_data/protein.fasta\")\n",
    "df1_1 = df1_1.filter(~col(\"value\").contains(\">\"))\n",
    "\n",
    "df1_1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+-----+\n",
      "|value                                                       |chars|\n",
      "+------------------------------------------------------------+-----+\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|M    |\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|E    |\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|E    |\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|I    |\n",
      "|MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK|T    |\n",
      "+------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_1_withchars = df1_1.withColumn(\"chars\", explode(split(col(\"value\"), \"\")))\n",
    "df1_1_withchars.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+\n",
      "|chars|  count|                freq|\n",
      "+-----+-------+--------------------+\n",
      "|    K|1684031|0.047061932111059086|\n",
      "|    F| 985877|0.027551319687021555|\n",
      "|    Q|1422769|  0.0397607039821235|\n",
      "|    E|2674664| 0.07474616297912196|\n",
      "|    T|2795042| 0.07811024669472166|\n",
      "+-----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_1_withchars.groupBy(\"chars\").count().withColumn(\"freq\",col(\"count\")/df1_1_withchars.count()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK',\n",
       " 'KKEVVAVAKKEEVLKKEVVVPSKKDEEILPLKKEVPRPPKKEEDVMPQKKEVPRPPKKEE',\n",
       " 'DIVPQMRDVSLPPKEEEKIVPKKKEVPRPPKKVEEILPPKKEVHRPPKKEEDIVPQIREV',\n",
       " 'SLPPKKDEEIVCEKKEVAPAKEEPSKKPKVPSLPATQREDVIEEIIHKKPTAALSKFEDV',\n",
       " 'KEHEEKETFVVLKKEIIDAPTKKEMVTAKHVIVPQKEEIIPSPTQEEVVSFKRKQTVRTS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1_2 = spark.sparkContext.textFile(\"data/Q1_data/protein.fasta\")\n",
    "rdd1_2 = rdd1_2.filter(lambda x: \">\" not in x)\n",
    "rdd1_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'E', 'E', 'I', 'T']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1_2_withchars = rdd1_2.flatMap(lambda x: list(x))\n",
    "rdd1_2_withchars.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'M': 0.013064028899518616,\n",
       " 'E': 0.07474616297912196,\n",
       " 'I': 0.04826036842051577,\n",
       " 'T': 0.07811024669472166,\n",
       " 'Q': 0.0397607039821235,\n",
       " 'K': 0.047061932111059086,\n",
       " 'R': 0.05001252679497514,\n",
       " 'L': 0.07969207419272037,\n",
       " 'S': 0.0767899658206434,\n",
       " 'V': 0.07715222983238408,\n",
       " 'G': 0.07415264580860985,\n",
       " 'D': 0.06195360153390011,\n",
       " 'N': 0.03680178138989157,\n",
       " 'H': 0.0175608199300819,\n",
       " 'P': 0.05862931292380984,\n",
       " 'A': 0.0900722250424395,\n",
       " 'C': 0.015774260028317683,\n",
       " 'F': 0.027551319687021555,\n",
       " 'Y': 0.023002241688475027,\n",
       " 'W': 0.009813685408233087,\n",
       " 'X': 3.7643263427808984e-05,\n",
       " 'B': 1.6767600635995093e-07,\n",
       " 'Z': 5.589200211998364e-08}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = rdd1_2_withchars.countByValue()\n",
    "total_count = rdd1_2_withchars.count()\n",
    "\n",
    "frequencies = {k: v / total_count for k, v in counts.items()}\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('M', 467474), ('E', 2674664), ('I', 1726915), ('Q', 1422769), ('K', 1684031)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1_2_withchars.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEEITQIKKRLSQTVRLEGKEDLLSKKDSITNLKTEEHVSVKKMVISEPKPEKKEDIQLK',\n",
       " 'KKEVVAVAKKEEVLKKEVVVPSKKDEEILPLKKEVPRPPKKEEDVMPQKKEVPRPPKKEE',\n",
       " 'DIVPQMRDVSLPPKEEEKIVPKKKEVPRPPKKVEEILPPKKEVHRPPKKEEDIVPQIREV',\n",
       " 'SLPPKKDEEIVCEKKEVAPAKEEPSKKPKVPSLPATQREDVIEEIIHKKPTAALSKFEDV',\n",
       " 'KEHEEKETFVVLKKEIIDAPTKKEMVTAKHVIVPQKEEIIPSPTQEEVVSFKRKQTVRTS']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1_2.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "rdd1_2.map(lambda x: list(re.findall(\"STAT\",x))).filter(lambda x: len(x)!=0).flatMap(lambda x: x).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.ui.port', 64050).appName(\"ass2_Q2\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+\n",
      "|     id|        course_title|                 url|   rating|num_reviews|num_published_lectures|            created|last_update_date|        duration|instructors_id|               image|\n",
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+\n",
      "| 567828|The Complete Pyth...|/course/complete-...|4.5927815|     452973|                   155|2015-07-29 00:12:23|      2021-03-14|  22 total hours|       9685726|https://img-c.ude...|\n",
      "|1565838|The Complete 2023...|/course/the-compl...| 4.667258|     263152|                   490|2018-02-22 12:02:33|      2023-01-20|65.5 total hours|      31334738|https://img-c.ude...|\n",
      "| 625204|The Web Developer...|/course/the-web-d...|4.6961474|     254711|                   616|2015-09-28 21:32:19|      2023-02-12|  64 total hours|       4466306|https://img-c.ude...|\n",
      "| 756150|Angular - The Com...|/course/the-compl...|4.5926924|     180257|                   472|2016-02-08 17:02:55|      2023-02-06|34.5 total hours|      13952972|https://img-c.ude...|\n",
      "|2776760|100 Days of Code:...|/course/100-days-...|4.6952515|     177568|                   676|2020-01-24 10:47:21|      2022-11-30|  64 total hours|      31334738|https://img-c.ude...|\n",
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = spark.read.csv(\"data/Q2_data/courses.csv\",header=True)\n",
    "course = course.withColumnRenamed(\"title\",\"course_title\")\n",
    "course = course.withColumn(\"created\",to_timestamp(\"created\", \"yyyy-MM-dd'T'HH:mm:ss'Z'\"))\n",
    "course.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "|_class|      id|    instructor_title|      name|        display_name|           job_title|         image_50x50|       image_100x100|initials|                 url|\n",
      "+------+--------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "|  user| 9685726|       Jose Portilla|      Jose|       Jose Portilla|Head of Data Scie...|https://img-c.ude...|https://img-c.ude...|      JP| /user/joseportilla/|\n",
      "|  user|31334738|       Dr. Angela Yu|Dr. Angela|       Dr. Angela Yu|Developer and Lea...|https://img-c.ude...|https://img-c.ude...|      DY|/user/4b4368a3-b5...|\n",
      "|  user| 4466306|         Colt Steele|      Colt|         Colt Steele|Developer and Boo...|https://img-b.ude...|https://img-b.ude...|      CS|   /user/coltsteele/|\n",
      "|  user|13952972|Maximilian Schwar...|Maximilian|Maximilian Schwar...|AWS certified, Pr...|https://img-b.ude...|https://img-b.ude...|      MS|/user/maximilian-...|\n",
      "|  user|  599932|        Tim Buchalka|       Tim|        Tim Buchalka|Java Python Andro...|https://img-c.ude...|https://img-c.ude...|      TB|  /user/timbuchalka/|\n",
      "+------+--------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructors = spark.read.csv(\"data/Q2_data/instructors.csv\",header=True)\n",
    "instructors = instructors.withColumnRenamed(\"title\",\"instructor_title\")\n",
    "instructors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83104 \n",
      " ['id', 'course_title', 'url', 'rating', 'num_reviews', 'num_published_lectures', 'created', 'last_update_date', 'duration', 'instructors_id', 'image']\n",
      "32233 \n",
      " ['_class', 'id', 'instructor_title', 'name', 'display_name', 'job_title', 'image_50x50', 'image_100x100', 'initials', 'url']\n"
     ]
    }
   ],
   "source": [
    "print(course.count(),\"\\n\",course.columns)\n",
    "print(instructors.count(),\"\\n\",instructors.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83094\n",
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+------+--------+----------------+----------+-------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "|     id|        course_title|                 url|   rating|num_reviews|num_published_lectures|            created|last_update_date|        duration|instructors_id|               image|_class|      id|instructor_title|      name| display_name|           job_title|         image_50x50|       image_100x100|initials|                 url|\n",
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+------+--------+----------------+----------+-------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "| 567828|The Complete Pyth...|/course/complete-...|4.5927815|     452973|                   155|2015-07-29 00:12:23|      2021-03-14|  22 total hours|       9685726|https://img-c.ude...|  user| 9685726|   Jose Portilla|      Jose|Jose Portilla|Head of Data Scie...|https://img-c.ude...|https://img-c.ude...|      JP| /user/joseportilla/|\n",
      "|1565838|The Complete 2023...|/course/the-compl...| 4.667258|     263152|                   490|2018-02-22 12:02:33|      2023-01-20|65.5 total hours|      31334738|https://img-c.ude...|  user|31334738|   Dr. Angela Yu|Dr. Angela|Dr. Angela Yu|Developer and Lea...|https://img-c.ude...|https://img-c.ude...|      DY|/user/4b4368a3-b5...|\n",
      "| 625204|The Web Developer...|/course/the-web-d...|4.6961474|     254711|                   616|2015-09-28 21:32:19|      2023-02-12|  64 total hours|       4466306|https://img-c.ude...|  user| 4466306|     Colt Steele|      Colt|  Colt Steele|Developer and Boo...|https://img-b.ude...|https://img-b.ude...|      CS|   /user/coltsteele/|\n",
      "+-------+--------------------+--------------------+---------+-----------+----------------------+-------------------+----------------+----------------+--------------+--------------------+------+--------+----------------+----------+-------------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_1 = course.join(instructors, course[\"instructors_id\"] == instructors[\"id\"], \"inner\")\n",
    "print(df2_1.count())\n",
    "df2_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32230"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_1.select(col(\"instructors_id\")).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------------------+\n",
      "|display_name|job_title                            |\n",
      "+------------+-------------------------------------+\n",
      "|Deby Coles  |Sewer, Artist, Crafter and Instructor|\n",
      "+------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_1.createOrReplaceTempView(\"df2_1\")\n",
    "spark.sql(\"select display_name, job_title from df2_1 where course_title like '%spark%' and created > '2018-01-01 00:00:00' order by rating desc LIMIT 1\").show(truncate=False)\n",
    "# spark.sql(\"select * from df2_1 where course_title like '%spark%' and created > '2018-01-01 00:00:00' order by rating desc LIMIT 1\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------+-------------------+\n",
      "|course                                                      |rating|created            |\n",
      "+------------------------------------------------------------+------+-------------------+\n",
      "|Réaliser des interviews au rendu professionnel (PARTIE 2)   |4.9   |2022-08-12 14:54:06|\n",
      "|Win your Product Management job interview with Big Tech's PM|4.8   |2022-08-26 10:43:53|\n",
      "|Get your Java dream job! Beginners interview preparation    |4.8   |2017-03-25 22:54:38|\n",
      "|Angular interview questions with answers                    |4.6   |2020-05-02 06:13:45|\n",
      "|Software Testing Interview Masterclass: Ace the QA interview|4.6   |2019-12-14 19:54:00|\n",
      "+------------------------------------------------------------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course.createOrReplaceTempView(\"course\")\n",
    "spark.sql(\"select course_title  as course,round(rating,1) as rating , created from course where course_title like '%interview%' order by rating desc, created desc\").show(5,truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
